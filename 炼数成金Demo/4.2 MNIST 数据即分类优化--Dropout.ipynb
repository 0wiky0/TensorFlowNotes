{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "Iter 0, Texting acc 0.9176, train_acc acc 0.91063637\n",
      "Iter 1, Texting acc 0.9297, train_acc acc 0.92710906\n",
      "Iter 2, Texting acc 0.9366, train_acc acc 0.9347818\n",
      "Iter 3, Texting acc 0.9403, train_acc acc 0.9399091\n",
      "Iter 4, Texting acc 0.9407, train_acc acc 0.9421091\n",
      "Iter 5, Texting acc 0.9457, train_acc acc 0.9474364\n",
      "Iter 6, Texting acc 0.948, train_acc acc 0.9508182\n",
      "Iter 7, Texting acc 0.9508, train_acc acc 0.9526909\n",
      "Iter 8, Texting acc 0.9537, train_acc acc 0.9563091\n",
      "Iter 9, Texting acc 0.955, train_acc acc 0.9577818\n",
      "Iter 10, Texting acc 0.9559, train_acc acc 0.9587455\n",
      "Iter 11, Texting acc 0.9579, train_acc acc 0.9605273\n",
      "Iter 12, Texting acc 0.9575, train_acc acc 0.9620182\n",
      "Iter 13, Texting acc 0.9582, train_acc acc 0.9641455\n",
      "Iter 14, Texting acc 0.9578, train_acc acc 0.9630909\n",
      "Iter 15, Texting acc 0.9581, train_acc acc 0.96501815\n",
      "Iter 16, Texting acc 0.9614, train_acc acc 0.9671091\n",
      "Iter 17, Texting acc 0.9617, train_acc acc 0.9681636\n",
      "Iter 18, Texting acc 0.9626, train_acc acc 0.9690545\n",
      "Iter 19, Texting acc 0.9644, train_acc acc 0.97041816\n",
      "Iter 20, Texting acc 0.9654, train_acc acc 0.9715818\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "\n",
    "# 载入数据集\n",
    "mnist = input_data.read_data_sets(\"MNIST_data\",one_hot=True)\n",
    "\n",
    "# 定义每个批次的大小\n",
    "batch_size = 100\n",
    "# 计算一共有多少个批次\n",
    "n_batch = mnist.train.num_examples // batch_size\n",
    "\n",
    "# # 根据样本样式定义创建占位符（1列）\n",
    "x = tf.placeholder(tf.float32,[None,784]) # 每张图的像素点信息： 28*28 = 784\n",
    "y = tf.placeholder(tf.float32,[None,10])  # 十个数字\n",
    "keep_prob = tf.placeholder(tf.float32)  \n",
    "\n",
    "# 定义神经网络的中间层\n",
    "# \n",
    "# （输入层784个数据，中间层2000个神经元）\n",
    "W1 = tf.Variable(tf.truncated_normal([784,2000],stddev=0.1)) \n",
    "b1 =  tf.Variable(tf.zeros([2000])+0.1)\n",
    "# 激活函数：tanh\n",
    "L1 = tf.nn.tanh(tf.matmul(x,W1) + b1)\n",
    "L1_drop =  tf.nn.dropout(L1,keep_prob)\n",
    "\n",
    "\n",
    "W2 = tf.Variable(tf.truncated_normal([2000,2000],stddev=0.1)) \n",
    "b2 =  tf.Variable(tf.zeros([2000])+0.1)\n",
    "L2 = tf.nn.tanh(tf.matmul(L1_drop,W2) + b2)\n",
    "L2_drop =  tf.nn.dropout(L2,keep_prob)\n",
    "\n",
    "\n",
    "W3 = tf.Variable(tf.truncated_normal([2000,1000],stddev=0.1)) \n",
    "b3 =  tf.Variable(tf.zeros([1000])+0.1)\n",
    "L3 = tf.nn.tanh(tf.matmul(L2_drop,W3) + b3)\n",
    "L3_drop =  tf.nn.dropout(L3,keep_prob)\n",
    "\n",
    "\n",
    "W4 = tf.Variable(tf.truncated_normal([1000,10],stddev=0.1)) \n",
    "b4 =  tf.Variable(tf.zeros([10])+0.1)\n",
    "L4 = tf.matmul(L3_drop,W4) + b4\n",
    "prediction = tf.nn.softmax(L4)\n",
    "\n",
    "\n",
    "# 二次代阶函数\n",
    "# loss = tf.reduce_mean(tf.square(y - prediction))\n",
    "\n",
    "# 交叉熵\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels = y, logits = prediction))\n",
    "\n",
    "# 定义一个梯度下降法来进行训练的优化器\n",
    "train =  tf.train.GradientDescentOptimizer(0.2).minimize(loss)\n",
    "\n",
    "# 结果存放在一个布尔型的列表中\n",
    "correct_prediction = tf.equal(tf.arg_max(y,1),tf.arg_max(prediction,1))# argmax 返回一维张量中最大值的所以在位置\n",
    "# 求准确率\n",
    "# cast 把布尔型列表转换为float32， 如[true.true.false] =》 [1,1,0] ，那么准确率的值即为66.6%\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "\n",
    "with tf.Session() as sess: \n",
    "    # 初始化全部变量\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    # 训练21个周期\n",
    "    for epoch in range(21):\n",
    "        # n_batch ： 一共有多少个批次\n",
    "        for batch in range(n_batch):\n",
    "            # 保存batch_size张图片的数据与标签\n",
    "            batch_xs,batch_ys = mnist.train.next_batch(batch_size)\n",
    "            sess.run(train,feed_dict={x:batch_xs,y:batch_ys,keep_prob:0.7})\n",
    "        \n",
    "        # 用测试集的图片及标签求得准确率\n",
    "        test_acc = sess.run(accuracy,feed_dict={x:mnist.test.images,y:mnist.test.labels,keep_prob:1.0})\n",
    "        train_acc = sess.run(accuracy,feed_dict={x:mnist.train.images,y:mnist.train.labels,keep_prob:1.0})\n",
    "        print(\"Iter \"+ str(epoch) + \", Texting acc \" + str(test_acc)+ \", train_acc acc \" + str(train_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-12-4ef772082e35>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-12-4ef772082e35>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    Iter 0, Texting acc 0.916, train_acc acc 0.91252726\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# keep_prob:1.0\n",
    "Iter 0, Texting acc 0.916, train_acc acc 0.91252726\n",
    "Iter 1, Texting acc 0.9349, train_acc acc 0.9340909\n",
    "Iter 2, Texting acc 0.9403, train_acc acc 0.9428545\n",
    "Iter 3, Texting acc 0.9499, train_acc acc 0.9536727\n",
    "Iter 4, Texting acc 0.9555, train_acc acc 0.96147275\n",
    "Iter 5, Texting acc 0.9575, train_acc acc 0.96494544\n",
    "Iter 6, Texting acc 0.9611, train_acc acc 0.96892726\n",
    "Iter 7, Texting acc 0.9648, train_acc acc 0.9719273\n",
    "Iter 8, Texting acc 0.9642, train_acc acc 0.97383636\n",
    "Iter 9, Texting acc 0.965, train_acc acc 0.9761091\n",
    "Iter 10, Texting acc 0.9657, train_acc acc 0.97845453\n",
    "Iter 11, Texting acc 0.9686, train_acc acc 0.9804\n",
    "Iter 12, Texting acc 0.9685, train_acc acc 0.9805091\n",
    "Iter 13, Texting acc 0.9699, train_acc acc 0.9826\n",
    "Iter 14, Texting acc 0.9697, train_acc acc 0.98383635\n",
    "Iter 15, Texting acc 0.9713, train_acc acc 0.9847818\n",
    "Iter 16, Texting acc 0.9714, train_acc acc 0.98507273\n",
    "Iter 17, Texting acc 0.9728, train_acc acc 0.98612726\n",
    "Iter 18, Texting acc 0.9723, train_acc acc 0.9864909\n",
    "Iter 19, Texting acc 0.9721, train_acc acc 0.9868909\n",
    "Iter 20, Texting acc 0.9737, train_acc acc 0.98783636"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# keep_prob:0.7\n",
    "Iter 0, Texting acc 0.9024, train_acc acc 0.8964546\n",
    "Iter 1, Texting acc 0.9187, train_acc acc 0.91532725\n",
    "Iter 2, Texting acc 0.9257, train_acc acc 0.9227273\n",
    "Iter 3, Texting acc 0.932, train_acc acc 0.92996365\n",
    "Iter 4, Texting acc 0.9355, train_acc acc 0.9347818\n",
    "Iter 5, Texting acc 0.9347, train_acc acc 0.93521816\n",
    "Iter 6, Texting acc 0.9412, train_acc acc 0.94136363\n",
    "Iter 7, Texting acc 0.9426, train_acc acc 0.94372725\n",
    "Iter 8, Texting acc 0.9458, train_acc acc 0.94576365\n",
    "Iter 9, Texting acc 0.947, train_acc acc 0.9490182\n",
    "Iter 10, Texting acc 0.9466, train_acc acc 0.9508182\n",
    "Iter 11, Texting acc 0.95, train_acc acc 0.95321816\n",
    "Iter 12, Texting acc 0.9509, train_acc acc 0.9540182\n",
    "Iter 13, Texting acc 0.9509, train_acc acc 0.95414543\n",
    "Iter 14, Texting acc 0.9532, train_acc acc 0.9573454\n",
    "Iter 15, Texting acc 0.9541, train_acc acc 0.9581636\n",
    "Iter 16, Texting acc 0.9546, train_acc acc 0.9584909\n",
    "Iter 17, Texting acc 0.956, train_acc acc 0.9596182\n",
    "Iter 18, Texting acc 0.9566, train_acc acc 0.96123636\n",
    "Iter 19, Texting acc 0.958, train_acc acc 0.9628\n",
    "Iter 20, Texting acc 0.9579, train_acc acc 0.9623273"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
